{
  "hash": "11c8e032f541089fae2c34b0c0213732",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Kernel density estimation in R spatial\"\ndescription: |\n  Here's one way to do kernel density estimation in R spatial\ndate: 10-21-2021\noutput:\n  distill::distill_article\n---\n\n\n## Packages\nThis requires a surprising number of moving parts (at least the way I did it):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(sf)\nlibrary(tmap)\nlibrary(spatstat)\nlibrary(raster)\nlibrary(dplyr)\n```\n:::\n\n\n## Data\nThe data are some [point data](abb.gpkg?raw=true) (Airbnb listings from [here](http://insideairbnb.com/new-zealand/)) and some [polygon data](sa2.gpkg?raw=true) (NZ census Statistical Area 2 data).\n\n### Load the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\npolys <- st_read(\"sa2.gpkg\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `sa2' from data source \n  `/Users/david/Documents/code/dosull.github.io/posts/2021-10-21-kde/sa2.gpkg' \n  using driver `GPKG'\nSimple feature collection with 78 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 1735096 ymin: 5419590 xmax: 1759041 ymax: 5443768\nProjected CRS: NZGD2000 / New Zealand Transverse Mercator 2000\n```\n\n\n:::\n\n```{.r .cell-code}\npts <- st_read(\"abb.gpkg\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `abb' from data source \n  `/Users/david/Documents/code/dosull.github.io/posts/2021-10-21-kde/abb.gpkg' \n  using driver `GPKG'\nSimple feature collection with 1254 features and 16 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 1742685 ymin: 5420357 xmax: 1755385 ymax: 5442630\nProjected CRS: NZGD2000 / New Zealand Transverse Mercator 2000\n```\n\n\n:::\n:::\n\n\nAnd have a look\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(polys) +\n  tm_polygons() + \n  tm_shape(pts) + \n  tm_dots()\n```\n\n::: {.cell-output-display}\n![](kde_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n## `spatstat` for density estimation\nThe best way I know to do density estimation in the _R_ ecosystem is using the [`spatstat`](https://spatstat.org/) library's specialisation of base _R_'s `density` function. That means converting the point data to a `spatstat` planar point pattern (`ppp`) object, which involves a couple of steps.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npts.ppp <- pts$geom %>% \n  as.ppp()\n```\n:::\n\n\nA point pattern also needs a 'window', which we'll make from the polygons.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npts.ppp$window <- polys %>%\n  st_union() %>%       # combine all the polygons into a single shape\n  as.owin()            # convert to spatstat owin - again maptools...\n```\n:::\n\n\n### Now the kernel density\nWe need some bounding box info to manage the density estimation resolution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbb <- st_bbox(polys)\ncellsize <- 100\nheight <- (bb$ymax - bb$ymin) / cellsize\nwidth <- (bb$xmax - bb$xmin) / cellsize\n```\n:::\n\n\nNow we specify the size of the raster we want with `dimyx` (note the order, y then x) using `height` and `width`. \n\nWe can convert this directly to a raster, but have to supply a CRS which we pull from the original points input dataset. At the time of writing (August 2021) you'll get a complaint about the New Zealand Geodetic Datum 2000 because recent changes in how projections and datums are handled are still working themselves out.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkde <- density(pts.ppp, sigma = 500, dimyx = c(height, width)) %>%\n  raster() \ncrs(kde) = st_crs(pts)$wkt  # a ppp has no CRS information so add it\n```\n:::\n\n\n### Let's see what we got\nWe can map this using `tmap`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(kde) +\n  tm_raster(palette =  \"Reds\")\n```\n\n::: {.cell-output-display}\n![](kde_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n### A fallback sanity check\nTo give us an alternative view of the data, let's just count points in polygons\n\n\n::: {.cell}\n\n```{.r .cell-code}\npolys$n <- polys %>%\n  st_contains(pts) %>%\n  lengths()\n```\n:::\n\n\nAnd map the result\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(polys) +\n  tm_polygons(col = \"n\", palette = \"Reds\", title = \"Points in polygons\")\n```\n\n::: {.cell-output-display}\n![](kde_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### Aggregate the density surface pixels to polygons\nThis isn't at all necessary, but is also useful to know. This is also a relatively slow operation. Note that we add together the density estimates in the pixels contained by each polygon.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummed_densities <- raster::extract(kde, polys, fun = sum)\n```\n:::\n\n\nAppend this to the polygons and rescale so the result is an estimate of the original count. We multiply by `cellsize^2` because each cell contains an estimate of the per sq metre (in this case, but per sq distance unit in general) density, so multiplying by the area of the cells gives an estimated count.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npolys$estimated_count = summed_densities[, 1] * cellsize ^ 2\n```\n:::\n\n\nAnd now we can make another map\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(polys) + \n  tm_polygons(col = \"estimated_count\", palette = \"Reds\",\n              title = \"500m KDE summed\")\n```\n\n::: {.cell-output-display}\n![](kde_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nSpot the deliberate mistake?! \n\nSomething doesn't seem quite right! What's with the large numbers in the large rural area to the west of the city? Thing is, you shouldn't really map count data like this, but should instead convert to densities. If we include that option in the `tm_polygons` function, then order is restored.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntm_shape(polys) + \n  tm_polygons(col = \"estimated_count\", palette = \"Reds\", convert2density = TRUE,\n              title = \"500m KDE estimate\")\n```\n\n::: {.cell-output-display}\n![](kde_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nReally, this should be done with the earlier map of points in polygons too, so let's show all three side by side. `tmap_arrange` is nice for this, although it has trouble making legend title font sizes match, unless you do some creative renaming. I've also multiplied the KDE result by 1,000,000 to convert the density to listings per sq. km, and we can see that the three maps are comparable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- tm_shape(kde * 1000000) + \n  tm_raster(palette = \"Reds\", title = \"500m KDE\")\nm2 <- tm_shape(polys) + \n  tm_fill(col = \"n\", palette = \"Blues\", convert2density = TRUE,\n              title = \"Point density\")\nm3 <- tm_shape(polys) + \n  tm_fill(col = \"estimated_count\", palette = \"Greens\", convert2density = TRUE,\n              title = \"KDE summed\")\ntmap_arrange(m1, m2, m3, nrow = 1)\n```\n\n::: {.cell-output-display}\n![](kde_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::",
    "supporting": [
      "kde_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}